{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Version 1.1.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The task"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this assignment you will need to implement features, based on nearest neighbours. \n",
    "\n",
    "KNN classifier (regressor) is a very powerful model, when the features are homogeneous and it is a very common practice to use KNN as first level model. In this homework we will extend KNN model and compute more features, based on nearest neighbors and their distances. \n",
    "\n",
    "You will need to implement a number of features, that were one of the key features, that leaded the instructors to prizes in [Otto](https://www.kaggle.com/c/otto-group-product-classification-challenge) and [Springleaf](https://www.kaggle.com/c/springleaf-marketing-response) competitions. Of course, the list of features you will need to implement can be extended, in fact in competitions the list was at least 3 times larger. So when solving a real competition do not hesitate to make up your own features.   \n",
    "\n",
    "You can optionally implement multicore feature computation. Nearest neighbours are hard to compute so it is preferable to have a parallel version of the algorithm. In fact, it is really a cool skill to know how to use `multiprocessing`, `joblib` and etc. In this homework you will have a chance to see the benefits of parallel algorithm. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check your versions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some functions we use here are not present in old versions of the libraries, so make sure you have up-to-date software. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "numpy 1.13.1\n",
      "pandas 0.20.3\n",
      "sklearn 0.19.0\n",
      "scipy 0.19.1\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd \n",
    "import sklearn\n",
    "import scipy.sparse \n",
    "from multiprocessing import Pool\n",
    "\n",
    "for p in [np, pd, sklearn, scipy]:\n",
    "    print (p.__name__, p.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The versions should be not less than:\n",
    "\n",
    "    numpy 1.13.1\n",
    "    pandas 0.20.3\n",
    "    sklearn 0.19.0\n",
    "    scipy 0.19.1\n",
    "   \n",
    "**IMPORTANT!** The results with `scipy=1.0.0` will be different! Make sure you use _exactly_ version `0.19.1`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Learn features and labels. These features are actually OOF predictions of linear models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_path = '../readonly/KNN_features_data/X.npz'\n",
    "train_labels = '../readonly/KNN_features_data/Y.npy'\n",
    "\n",
    "test_path = '../readonly/KNN_features_data/X_test.npz'\n",
    "test_labels = '../readonly/KNN_features_data/Y_test.npy'\n",
    "\n",
    "# Train data\n",
    "X = scipy.sparse.load_npz(train_path)\n",
    "Y = np.load(train_labels)\n",
    "\n",
    "# Test data\n",
    "X_test = scipy.sparse.load_npz(test_path)\n",
    "Y_test = np.load(test_labels)\n",
    "\n",
    "# Out-of-fold features we loaded above were generated with n_splits=4 and skf seed 123\n",
    "# So it is better to use seed 123 for generating KNN features as well \n",
    "skf_seed = 123\n",
    "n_splits = 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>How to use KNN for feature generation</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<1x52418 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 5 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[1:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below you need to implement features, based on nearest neighbors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.neighbors import NearestNeighbors\n",
    "nn = NearestNeighbors(n_neighbors=10, \n",
    "                                      n_jobs=1, \n",
    "                                      algorithm='brute')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "here n_neighbors is the max number of neighbors to compute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "XX = X[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "res = nn.fit(XX)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "predict neighbor for only one X point (XX[1:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "neighs_dist, neighs =res.kneighbors(XX[1:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1 95 29 87 59 72 41 43 18 94]] [[ 0.          1.41421356  1.41421356  1.41421356  1.41421356  1.41421356\n",
      "   1.41421356  1.41421356  1.41421356  1.41421356]]\n"
     ]
    }
   ],
   "source": [
    "print(neighs, neighs_dist)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "neighs is the index of the 10 closests neighbor to XX[1:2]<br>\n",
    "neighs_dist is the distances of the 10 closests neighbor to XX[1:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "YY = Y[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "neighs_y = YY[neighs[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[26  0  0 19 22 14  8 11  1 13]\n"
     ]
    }
   ],
   "source": [
    "print(neighs_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "this are the labels for the 10 closest neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[26  0  0 19 22]\n"
     ]
    }
   ],
   "source": [
    "k = 5\n",
    "k_closest_neighs_y = neighs_y[:k]\n",
    "print(k_closest_neighs_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "this are the labels of the k closest neighbors to XX[1:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 1]\n"
     ]
    }
   ],
   "source": [
    "classes_count = np.bincount(k_closest_neighs_y)\n",
    "print(classes_count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "for every class (where index of classes_count is the class number) the number of times it appear in k_closest_neight_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_classes = 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "feats = [0 for _ in range(n_classes)]\n",
    "class_counts = np.bincount(neighs_y[1:k+1])\n",
    "total_classes = sum(class_counts)\n",
    "for class_number in range(n_classes):\n",
    "    if class_number < len(class_counts):\n",
    "        feats[class_number] = class_counts[class_number] / total_classes\n",
    "assert len(feats) == n_classes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " 1. Fraction of objects of every class.\n",
    "               It is basically a KNNÐ¡lassifiers predictions.\n",
    "\n",
    "               Take a look at `np.bincount` function, it can be very helpful\n",
    "               Note that the values should sum up to one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.40000000000000002, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.20000000000000001, 0.0, 0.0, 0.0, 0.0, 0.20000000000000001, 0.0, 0.0, 0.20000000000000001, 0, 0, 0, 0, 0, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "print(feats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "assert sum(feats) == 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ True, False, False, False, False, False, False, False, False, False], dtype=bool)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "neighs_y == neighs_y[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.  1.  2.]\n",
      " [ 3.  4.  5.]\n",
      " [ 6.  7.  8.]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([2, 2, 2]), array([0, 1, 2]))"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = np.arange(9.).reshape(3, 3)\n",
    "print(x)\n",
    "np.where(x > 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "for point 2. I dont'really know how to use np.where ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n"
     ]
    }
   ],
   "source": [
    "neighs_y = [1,1,1,5,2,7,5]\n",
    "'''\n",
    "    2. Same label streak: the largest number N, \n",
    "       such that N nearest neighbors have the same label.\n",
    "\n",
    "       What can help you: `np.where`\n",
    "'''\n",
    "\n",
    "res = 1\n",
    "first_class = neighs_y[0]\n",
    "for i in range(1,len(neighs_y)):\n",
    "    if neighs_y[i] == first_class: res += 1\n",
    "    else: break\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "neighs_y = YY[neighs[0]]\n",
    "neighs_dist = neighs_dist[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[26  0  0 19 22 14  8 11  1 13]\n",
      "[ 0.          1.41421356  1.41421356  1.41421356  1.41421356  1.41421356\n",
      "  1.41421356  1.41421356  1.41421356  1.41421356]\n"
     ]
    }
   ],
   "source": [
    "print(neighs_y)\n",
    "print(neighs_dist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.4142135623730949, 1.4142135623730949, 999, 999, 999, 999, 999, 999, 1.4142135623730949, 999, 999, 1.4142135623730949, 999, 1.4142135623730949, 1.4142135623730949, 999, 999, 999, 999, 1.4142135623730949, 999, 999, 1.4142135623730949, 999, 999, 999, 0.0, 999, 999, 999]\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "    3. Minimum distance to objects of each class\n",
    "       Find the first instance of a class and take its distance as features.\n",
    "\n",
    "       If there are no neighboring objects of some classes, \n",
    "       Then set distance to that class to be 999.\n",
    "\n",
    "       `np.where` might be helpful\n",
    "'''\n",
    "feats = [999 for _ in range(n_classes)]\n",
    "for i, _class in enumerate(neighs_y):\n",
    "    feats[_class] = min(neighs_dist[i], feats[_class])\n",
    "\n",
    "print(feats)\n",
    "assert len(feats) == n_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.4142135623730949"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "min(neighs_dist[1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.99999929289371892, 0.99999929289371892, 706.39917490571429, 706.39917490571429, 706.39917490571429, 706.39917490571429, 706.39917490571429, 706.39917490571429, 0.99999929289371892, 706.39917490571429, 706.39917490571429, 0.99999929289371892, 706.39917490571429, 0.99999929289371892, 0.99999929289371892, 706.39917490571429, 706.39917490571429, 706.39917490571429, 706.39917490571429, 0.99999929289371892, 706.39917490571429, 706.39917490571429, 0.99999929289371892, 706.39917490571429, 706.39917490571429, 706.39917490571429, 0.0, 706.39917490571429, 706.39917490571429, 706.39917490571429]\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "    4. Minimum *normalized* distance to objects of each class\n",
    "       As 3. but we normalize (divide) the distances\n",
    "       by the distance to the closest neighbor.\n",
    "\n",
    "       If there are no neighboring objects of some classes, \n",
    "       Then set distance to that class to be 999.\n",
    "\n",
    "       Do not forget to add self.eps to denominator.\n",
    "'''\n",
    "distance_to_closest = min(neighs_dist[1:]) + 1e-6\n",
    "feats = [999 / (distance_to_closest) for _ in range(n_classes)] # should I normalize also 999?\n",
    "for i, _class in enumerate(neighs_y):\n",
    "    feats[_class] = min(neighs_dist[i] / distance_to_closest, feats[_class])\n",
    "\n",
    "print(feats)\n",
    "assert len(feats) == n_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.4142135623730949, 0.99999929289371892]]\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "    5. \n",
    "       5.1 Distance to Kth neighbor\n",
    "           Think of this as of quantiles of a distribution\n",
    "       5.2 Distance to Kth neighbor normalized by \n",
    "           distance to the first neighbor\n",
    "\n",
    "       feat_51, feat_52 are answers to 5.1. and 5.2.\n",
    "       should be scalars\n",
    "\n",
    "       Do not forget to add self.eps to denominator.\n",
    "'''\n",
    "for k in [2,4,8]:\n",
    "\n",
    "    feat_51 = neighs_dist[k - 1] #distances is zero based\n",
    "    feat_52 = neighs_dist[k - 1] / distance_to_closest\n",
    "\n",
    "print([[feat_51, feat_52]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.4142135623730949"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k = 10\n",
    "neighs_dist[k - 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(neighs_dist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([26,  0,  0, 19, 22, 14,  8, 11,  1, 13])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "neighs_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.        ,  1.41421356,  1.41421356,  1.41421356,  1.41421356,\n",
       "        1.41421356,  1.41421356,  1.41421356,  1.41421356,  1.41421356])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "neighs_dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 2.82842712  1.41421356  0.          0.          0.          0.          0.\n",
      "  0.          1.41421356  0.          0.          1.41421356  0.\n",
      "  1.41421356  1.41421356  0.          0.          0.          0.\n",
      "  1.41421356  0.          0.          1.41421356  0.          0.          0.\n",
      "  0.        ]\n",
      "[2 1 0 0 0 0 0 0 1 0 0 1 0 1 1 0 0 0 0 1 0 0 1 0 0 0 1]\n",
      "[ 1.41421286  1.41421215  0.          0.          0.          0.          0.\n",
      "  0.          1.41421215  0.          0.          1.41421215  0.\n",
      "  1.41421215  1.41421215  0.          0.          0.          0.\n",
      "  1.41421215  0.          0.          1.41421215  0.          0.          0.\n",
      "  0.        ]\n"
     ]
    }
   ],
   "source": [
    "print(np.bincount(neighs_y, neighs_dist)) #this bincount with distances as weight\n",
    "print(np.bincount(neighs_y)) #this bincount with distances as weight\n",
    "mean_classes = np.bincount(neighs_y, neighs_dist) / (np.bincount(neighs_y) + 1e-6) #this is mean of classes with distances\n",
    "print(mean_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ True,  True, False, False, False, False, False, False,  True,\n",
       "       False, False,  True, False,  True,  True, False, False, False,\n",
       "       False,  True, False, False,  True, False, False, False, False], dtype=bool)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_classes > 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.4142128552666673, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999]\n",
      "[1.4142128552666673, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 1.4142121481609469, 999, 999, 1.4142121481609469, 999, 999, 999, 999, 999, 999, 999]\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "    6. Mean distance to neighbors (of x) belonging each class for each K from `k_list` \n",
    "           For each class select the neighbors of x belonging to that speficics class among K nearest neighbors \n",
    "           and compute the average distance from x to those objects\n",
    "\n",
    "           If there are no objects of a certain class among K neighbors, set mean distance to 999\n",
    "\n",
    "       You can use `np.bincount` with appropriate weights\n",
    "       Don't forget, that if you divide by something, \n",
    "       You need to add `self.eps` to denominator.\n",
    "'''\n",
    "for k in [2,4]:\n",
    "    feats = [999 for _ in range(n_classes)]\n",
    "    k_closest_neighs_y = neighs_y[1:k + 1]\n",
    "    k_neighs_dist = neighs_dist[1:k + 1]\n",
    "    mean_distance_classes = np.bincount(k_closest_neighs_y, k_neighs_dist) / (np.bincount(k_closest_neighs_y) + 1e-6)\n",
    "    for i, _class in enumerate(mean_distance_classes):\n",
    "        if _class > 0:\n",
    "            feats[i] = _class\n",
    "    \n",
    "    print(feats)\n",
    "    assert len(feats) == n_classes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "<h1>How to implement multiprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from tqdm import tqdm_notebook as tqdm\n",
    "def _compute_feats(_X):\n",
    "    test_feats = []\n",
    "    for i in tqdm(range(_X.shape[0])):\n",
    "        for _ in range(300): pass\n",
    "        feats = np.arange(2) # of course this is a mock of the real compute feats\n",
    "        assert feats.shape == (2,) or feats.shape == (2, 1)\n",
    "        test_feats.append(feats)\n",
    "    return test_feats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "this above is the compute function we want to separate in multiple threads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6ecea857a26d415cbf4eb9739261e3a4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0.21630549430847168\n"
     ]
    }
   ],
   "source": [
    "from time import time\n",
    "t1 = time()\n",
    "got = _compute_feats(X_test)\n",
    "print(time() - t1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12569"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "int(X.shape[0]/4) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 1397\n",
      "1397 2794\n",
      "2794 4191\n",
      "4191 5586\n",
      "[<1397x52418 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 7647 stored elements in Compressed Sparse Row format>, <1397x52418 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 7635 stored elements in Compressed Sparse Row format>, <1397x52418 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 7411 stored elements in Compressed Sparse Row format>, <1395x52418 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 7464 stored elements in Compressed Sparse Row format>]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a2e59ca1d5be439bb2fea681377e0e03",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e6dc729e638c4220b6b553c62dce67cc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "[array([0, 1]), array([0, 1]), array([0, 1]), array([0, 1]), array([0, 1]), array([0, 1]), array([0, 1]), array([0, 1]), array([0, 1]), array([0, 1])]\n",
      "[array([0, 1]), array([0, 1]), array([0, 1]), array([0, 1]), array([0, 1]), array([0, 1]), array([0, 1]), array([0, 1]), array([0, 1]), array([0, 1])]\n",
      "[array([0, 1]), array([0, 1]), array([0, 1]), array([0, 1]), array([0, 1]), array([0, 1]), array([0, 1]), array([0, 1]), array([0, 1]), array([0, 1])]\n",
      "[array([0, 1]), array([0, 1]), array([0, 1]), array([0, 1]), array([0, 1]), array([0, 1]), array([0, 1]), array([0, 1]), array([0, 1]), array([0, 1])]\n",
      "\n",
      "1.089226245880127\n"
     ]
    }
   ],
   "source": [
    "\"\"\"this is a good multiprocessing implementation including TQDM\n",
    "X: input np array to splitted\n",
    "_compute_feats: function that will be applied to chunks of X\n",
    "\"\"\"\n",
    "\n",
    "from multiprocessing import Pool\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "n_jobs = 4\n",
    "\n",
    "from time import time\n",
    "\n",
    "pool = Pool(n_jobs)\n",
    "splitted = []\n",
    "prev = 0\n",
    "for x in range(n_jobs):\n",
    "    i = min(prev + int(X_test.shape[0]/n_jobs) + 1, X_test.shape[0])\n",
    "    print(prev, i)\n",
    "    splitted.append(X_test[prev:i])\n",
    "    prev = i\n",
    "print(splitted) # we splitted the dataset in n_jobs chunks\n",
    "\n",
    "t1 = time()\n",
    "res = []\n",
    "with Pool(processes=n_jobs) as p:\n",
    "        max_ = 30\n",
    "        with tqdm(total=len(splitted)) as pbar:\n",
    "            for i, _res in tqdm(enumerate(p.imap_unordered(_compute_feats, splitted))):\n",
    "                print(_res[:10])\n",
    "                res.append(_res)\n",
    "                pbar.update()\n",
    "#res = tqdm_notebook(pool.imap(_compute_feats, splitted)) # now we apply the compute function\n",
    "test_feats = [elem for sublist in res for elem in sublist] # and we recombintest_feats\n",
    "print(time() - t1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5586, 5586)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(got),len(test_feats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([array([0, 1]), array([0, 1])], [array([0, 1]), array([0, 1])])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_feats[:2], got[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 1],\n",
       "       [0, 1],\n",
       "       [0, 1],\n",
       "       ..., \n",
       "       [0, 1],\n",
       "       [0, 1],\n",
       "       [0, 1]])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.vstack(test_feats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "del splitted\n",
    "del got\n",
    "del test_feats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, ClassifierMixin\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from multiprocessing import Pool\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "class NearestNeighborsFeats(BaseEstimator, ClassifierMixin):\n",
    "    '''\n",
    "        This class should implement KNN features extraction \n",
    "    '''\n",
    "    def __init__(self, n_jobs, k_list, metric, n_classes=None, n_neighbors=None, eps=1e-6):\n",
    "        self.n_jobs = n_jobs\n",
    "        self.k_list = k_list\n",
    "        self.metric = metric\n",
    "        \n",
    "        if n_neighbors is None:\n",
    "            self.n_neighbors = max(k_list) \n",
    "        else:\n",
    "            self.n_neighbors = n_neighbors\n",
    "            \n",
    "        self.eps = eps        \n",
    "        self.n_classes_ = n_classes\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        '''\n",
    "            Set's up the train set and self.NN object\n",
    "        '''\n",
    "        # Create a NearestNeighbors (NN) object. We will use it in `predict` function \n",
    "        self.NN = NearestNeighbors(n_neighbors=max(self.k_list), \n",
    "                                      metric=self.metric, \n",
    "                                      n_jobs=1, \n",
    "                                      algorithm='brute' if self.metric=='cosine' else 'auto')\n",
    "        self.NN.fit(X)\n",
    "        \n",
    "        # Store labels \n",
    "        self.y_train = y\n",
    "        \n",
    "        # Save how many classes we have\n",
    "        self.n_classes = np.unique(y).shape[0] if self.n_classes_ is None else self.n_classes_\n",
    "        \n",
    "    def compute_feats(self, _X):\n",
    "        test_feats = []\n",
    "        for i in tqdm(range(_X.shape[0])):\n",
    "            test_feats.append(self.get_features_for_one(_X[i:i+1]))\n",
    "        return test_feats\n",
    "        \n",
    "        \n",
    "    def predict(self, X):       \n",
    "        '''\n",
    "            Produces KNN features for every object of a dataset X\n",
    "        '''\n",
    "               \n",
    "        if self.n_jobs == 1:\n",
    "            test_feats = self.compute_feats(X)\n",
    "        else:\n",
    "            #splits X\n",
    "            splitted = []\n",
    "            prev = 0\n",
    "            for x in range(self.n_jobs):\n",
    "                i = min(prev + int(X.shape[0]/self.n_jobs) + 1, X.shape[0])\n",
    "                print(prev, i)\n",
    "                splitted.append(X[prev:i])\n",
    "                prev = i\n",
    "                \n",
    "            #start processes\n",
    "            res = []\n",
    "            with Pool(processes=self.n_jobs) as p:\n",
    "                max_ = 30\n",
    "                with tqdm(total=len(splitted)) as pbar:\n",
    "                    for i, _res in tqdm(enumerate(p.imap_unordered(self.compute_feats, splitted))):\n",
    "                        res.append(_res)\n",
    "                        pbar.update()\n",
    "            \n",
    "            test_feats = [elem for sublist in res for elem in sublist] # and we recombintest_feats\n",
    "\n",
    "    \n",
    "        return np.vstack(test_feats)\n",
    "        \n",
    "        \n",
    "    def get_features_for_one(self, x):\n",
    "        '''\n",
    "            Computes KNN features for a single object `x`\n",
    "        '''\n",
    "\n",
    "        NN_output = self.NN.kneighbors(x)\n",
    "        \n",
    "        # Vector of size `n_neighbors`\n",
    "        # Stores indices of the neighbors\n",
    "        neighs = NN_output[1][0]\n",
    "        \n",
    "        # Vector of size `n_neighbors`\n",
    "        # Stores distances to corresponding neighbors\n",
    "        neighs_dist = NN_output[0][0] \n",
    "\n",
    "        # Vector of size `n_neighbors`\n",
    "        # Stores labels of corresponding neighbors\n",
    "        neighs_y = self.y_train[neighs] \n",
    "        \n",
    "        ## ========================================== ##\n",
    "        ##              YOUR CODE BELOW\n",
    "        ## ========================================== ##\n",
    "        \n",
    "        # We will accumulate the computed features here\n",
    "        # Eventually it will be a list of lists or np.arrays\n",
    "        # and we will use np.hstack to concatenate those\n",
    "        return_list = [] \n",
    "        \n",
    "        \n",
    "        ''' \n",
    "            1. Fraction of objects of every class.\n",
    "               It is basically a KNNÐ¡lassifiers predictions.\n",
    "\n",
    "               Take a look at `np.bincount` function, it can be very helpful\n",
    "               Note that the values should sum up to one\n",
    "        '''\n",
    "        for k in self.k_list:\n",
    "            feats = [0 for _ in range(self.n_classes)]\n",
    "            class_counts = np.bincount(neighs_y[:k]) # distance is zero based, might get out of bound\n",
    "            total_classes = sum(class_counts)\n",
    "            for class_number in range(self.n_classes):\n",
    "                if class_number < len(class_counts):\n",
    "                    feats[class_number] = class_counts[class_number] / total_classes\n",
    "            \n",
    "            assert len(feats) == self.n_classes\n",
    "            assert 0.999 <= sum(feats) <= 1.001\n",
    "            return_list += [feats]\n",
    "        \n",
    "        \n",
    "        '''\n",
    "            2. Same label streak: the largest number N, \n",
    "               such that N nearest neighbors have the same label.\n",
    "               \n",
    "               What can help you: `np.where`\n",
    "        '''\n",
    "        res = 1\n",
    "        first_class = neighs_y[0]\n",
    "        for i in range(1,len(neighs_y)):\n",
    "            if neighs_y[i] == first_class: res += 1\n",
    "            else: break\n",
    "        feats = [res]\n",
    "        \n",
    "        assert len(feats) == 1\n",
    "        return_list += [feats]\n",
    "        \n",
    "        '''\n",
    "            3. Minimum distance to objects of each class\n",
    "               Find the first instance of a class and take its distance as features.\n",
    "               \n",
    "               If there are no neighboring objects of some classes, \n",
    "               Then set distance to that class to be 999.\n",
    "\n",
    "               `np.where` might be helpful\n",
    "        '''\n",
    "        feats = [999 for _ in range(self.n_classes)]\n",
    "        for i, _class in enumerate(neighs_y):\n",
    "            feats[_class] = min(neighs_dist[i], feats[_class])\n",
    "\n",
    "        assert len(feats) == self.n_classes\n",
    "        return_list += [feats]\n",
    "        \n",
    "        '''\n",
    "            4. Minimum *normalized* distance to objects of each class\n",
    "               As 3. but we normalize (divide) the distances\n",
    "               by the distance to the closest neighbor.\n",
    "               \n",
    "               If there are no neighboring objects of some classes, \n",
    "               Then set distance to that class to be 999.\n",
    "               \n",
    "               Do not forget to add self.eps to denominator.\n",
    "        '''\n",
    "        distance_to_closest = neighs_dist[0]\n",
    "        feats = [999 for _ in range(self.n_classes)] \n",
    "        for i, _class in enumerate(neighs_y):\n",
    "            if feats[_class] == 999:\n",
    "                feats[_class] = (neighs_dist[i] / (distance_to_closest + self.eps))\n",
    "\n",
    "        assert len(feats) == self.n_classes\n",
    "        return_list += [feats]\n",
    "        \n",
    "        '''\n",
    "            5. \n",
    "               5.1 Distance to Kth neighbor\n",
    "                   Think of this as of quantiles of a distribution\n",
    "               5.2 Distance to Kth neighbor normalized by \n",
    "                   distance to the first neighbor\n",
    "               \n",
    "               feat_51, feat_52 are answers to 5.1. and 5.2.\n",
    "               should be scalars\n",
    "               \n",
    "               Do not forget to add self.eps to denominator.\n",
    "        '''\n",
    "        for k in self.k_list:\n",
    "            \n",
    "            feat_51 = neighs_dist[k - 1] #distances is zero based\n",
    "            feat_52 = neighs_dist[k - 1] / (distance_to_closest + self.eps)\n",
    "\n",
    "            return_list += [[feat_51, feat_52]]\n",
    "        \n",
    "        '''\n",
    "            6. Mean distance to neighbors of each class for each K from `k_list` \n",
    "                   For each class select the neighbors of that class among K nearest neighbors \n",
    "                   and compute the average distance to those objects\n",
    "                   \n",
    "                   If there are no objects of a certain class among K neighbors, set mean distance to 999\n",
    "                   \n",
    "               You can use `np.bincount` with appropriate weights\n",
    "               Don't forget, that if you divide by something, \n",
    "               You need to add `self.eps` to denominator.\n",
    "        '''\n",
    "        for k in self.k_list:\n",
    "            feats = [999 for _ in range(self.n_classes)]\n",
    "            k_closest_neighs_y = neighs_y[:k]\n",
    "            k_neighs_dist = neighs_dist[:k]\n",
    "            mean_distance_classes = np.bincount(k_closest_neighs_y, k_neighs_dist) / (np.bincount(k_closest_neighs_y) + self.eps)\n",
    "            for i, _class in enumerate(mean_distance_classes):\n",
    "                if _class > 0:\n",
    "                    feats[i] = _class\n",
    "\n",
    "\n",
    "            assert len(feats) == self.n_classes\n",
    "            return_list += [feats]\n",
    "        \n",
    "        \n",
    "        # merge\n",
    "        knn_feats = np.hstack(return_list)\n",
    "        \n",
    "        assert knn_feats.shape == (239,) or knn_feats.shape == (239, 1)\n",
    "        return knn_feats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sanity check"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To make sure you've implemented everything correctly we provide you the correct features for the first 50 objects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7414cf2b59ca4a848a65db9a345b48d1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Deviation from ground thruth features: 0.000000\n"
     ]
    }
   ],
   "source": [
    "# a list of K in KNN, starts with one \n",
    "k_list = [3, 8, 32]\n",
    "\n",
    "# Load correct features\n",
    "true_knn_feats_first50 = np.load('../readonly/KNN_features_data/knn_feats_test_first50.npy')\n",
    "\n",
    "# Create instance of our KNN feature extractor\n",
    "NNF = NearestNeighborsFeats(n_jobs=1, k_list=k_list, metric='minkowski')\n",
    "\n",
    "# Fit on train set\n",
    "NNF.fit(X, Y)\n",
    "\n",
    "# Get features for test\n",
    "test_knn_feats = NNF.predict(X_test[:50])\n",
    "\n",
    "# This should be zero\n",
    "print ('Deviation from ground thruth features: %f' % np.abs(test_knn_feats - true_knn_feats_first50).sum())\n",
    "\n",
    "deviation =np.abs(test_knn_feats - true_knn_feats_first50).sum(0)\n",
    "for m in np.where(deviation > 1e-3)[0]: \n",
    "    p = np.where(np.array([87, 88, 117, 146, 152, 239]) > m)[0][0]\n",
    "    print ('There is a problem in feature %d, which is a part of section %d.' % (m, p + 1))\n",
    "    for i in range(50):\n",
    "        if test_knn_feats[i][m] != true_knn_feats_first50[i][m]:\n",
    "            print (i, test_knn_feats[i][m], true_knn_feats_first50[i][m])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[   0.        ,    0.        ,    0.        , ...,  999.        ,\n",
       "         999.        ,  999.        ],\n",
       "       [   0.        ,    0.        ,    0.        , ...,  999.        ,\n",
       "           1.31804749,  999.        ],\n",
       "       [   0.        ,    0.        ,    0.        , ...,  999.        ,\n",
       "         999.        ,  999.        ],\n",
       "       ..., \n",
       "       [   1.        ,    0.        ,    0.        , ...,  999.        ,\n",
       "         999.        ,  999.        ],\n",
       "       [   0.        ,    0.        ,    0.        , ...,  999.        ,\n",
       "         999.        ,  999.        ],\n",
       "       [   0.        ,    0.        ,    0.        , ...,  999.        ,\n",
       "           1.24359388,    1.26195733]])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_knn_feats[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now implement parallel computations and compute features for the train and test sets. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get features for test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now compute features for the whole test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "minkowski\n",
      "0 1397\n",
      "1397 2794\n",
      "2794 4191\n",
      "4191 5586\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "64b12aebffe34c39a550d898a083923c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "290976e3221d4b4d8cd0082c7fef3f64",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "cosine\n",
      "0 1397\n",
      "1397 2794\n",
      "2794 4191\n",
      "4191 5586\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7104925baef341fb97042785c8b504ac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3d2b87bc46d54bc1af55fc37a1e1c11f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for metric in ['minkowski', 'cosine']:\n",
    "    print (metric)\n",
    "    \n",
    "    # Create instance of our KNN feature extractor\n",
    "    NNF = NearestNeighborsFeats(n_jobs=4, k_list=k_list, metric=metric)\n",
    "    \n",
    "    # Fit on train set\n",
    "    NNF.fit(X, Y)\n",
    "\n",
    "    # Get features for test\n",
    "    test_knn_feats = NNF.predict(X_test)\n",
    "    \n",
    "    # Dump the features to disk\n",
    "    np.save('knn_feats_%s_test.npy' % metric , test_knn_feats)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get features for train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute features for train, using out-of-fold strategy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "skf = StratifiedKFold(n_splits=n_splits, random_state=skf_seed, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_predict\n",
    "#cross_val_predict(NNF, X, Y, cv=skf, n_jobs=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "minkowski\n",
      "NNF\n",
      "0 839\n",
      "839 1678\n",
      "1678 2517\n",
      "2517 3356\n",
      "3356 4195\n",
      "4195 5034\n",
      "5034 5873\n",
      "5873 6712\n",
      "6712 7551\n",
      "7551 8390\n",
      "8390 9229\n",
      "9229 10068\n",
      "10068 10907\n",
      "10907 11746\n",
      "11746 12578\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f2fa70f30e5d4e53b0d5db4b5171d487",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1d4854c730f54490aa810abb6115fcba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "0 839\n",
      "839 1678\n",
      "1678 2517\n",
      "2517 3356\n",
      "3356 4195\n",
      "4195 5034\n",
      "5034 5873\n",
      "5873 6712\n",
      "6712 7551\n",
      "7551 8390\n",
      "8390 9229\n",
      "9229 10068\n",
      "10068 10907\n",
      "10907 11746\n",
      "11746 12572\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1c6541a4fe9749e1824a5d53829954d0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d9e53865100749dfaef6c3d3cc71fd96",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "0 838\n",
      "838 1676\n",
      "1676 2514\n",
      "2514 3352\n",
      "3352 4190\n",
      "4190 5028\n",
      "5028 5866\n",
      "5866 6704\n",
      "6704 7542\n",
      "7542 8380\n",
      "8380 9218\n",
      "9218 10056\n",
      "10056 10894\n",
      "10894 11732\n",
      "11732 12568\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d78174f248d442c4a06b1d8132276edd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9f57b5c271584f84b83e66b919b15e28",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "0 838\n",
      "838 1676\n",
      "1676 2514\n",
      "2514 3352\n",
      "3352 4190\n",
      "4190 5028\n",
      "5028 5866\n",
      "5866 6704\n",
      "6704 7542\n",
      "7542 8380\n",
      "8380 9218\n",
      "9218 10056\n",
      "10056 10894\n",
      "10894 11732\n",
      "11732 12556\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0d9e6037d09a46f9ade99612b34d0ba5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ddab3bc87e964400a144852f03ae13b8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "cosine\n",
      "NNF\n",
      "0 839\n",
      "839 1678\n",
      "1678 2517\n",
      "2517 3356\n",
      "3356 4195\n",
      "4195 5034\n",
      "5034 5873\n",
      "5873 6712\n",
      "6712 7551\n",
      "7551 8390\n",
      "8390 9229\n",
      "9229 10068\n",
      "10068 10907\n",
      "10907 11746\n",
      "11746 12578\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e771fff236da4a2ba44ed7a91a073376",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e0a04db1cb994e9e875d6335e0479f81",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "0 839\n",
      "839 1678\n",
      "1678 2517\n",
      "2517 3356\n",
      "3356 4195\n",
      "4195 5034\n",
      "5034 5873\n",
      "5873 6712\n",
      "6712 7551\n",
      "7551 8390\n",
      "8390 9229\n",
      "9229 10068\n",
      "10068 10907\n",
      "10907 11746\n",
      "11746 12572\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2f1a8859912c4ae78a454fe7a8df48ec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "00e4ff763bdf4337a17c034ba6bca908",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "0 838\n",
      "838 1676\n",
      "1676 2514\n",
      "2514 3352\n",
      "3352 4190\n",
      "4190 5028\n",
      "5028 5866\n",
      "5866 6704\n",
      "6704 7542\n",
      "7542 8380\n",
      "8380 9218\n",
      "9218 10056\n",
      "10056 10894\n",
      "10894 11732\n",
      "11732 12568\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fb34423810d54d788aae8b14f9e20f86",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ce00332a84f44af09280a4762aa249e1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "0 838\n",
      "838 1676\n",
      "1676 2514\n",
      "2514 3352\n",
      "3352 4190\n",
      "4190 5028\n",
      "5028 5866\n",
      "5866 6704\n",
      "6704 7542\n",
      "7542 8380\n",
      "8380 9218\n",
      "9218 10056\n",
      "10056 10894\n",
      "10894 11732\n",
      "11732 12556\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "131396dcc6e24665b67e4e4afbfbabfe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "051441df04304735acab1af81d5752c0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Differently from other homework we will not implement OOF predictions ourselves\n",
    "# but use sklearn's `cross_val_predict`\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "# We will use two metrics for KNN\n",
    "for metric in ['minkowski', 'cosine']:\n",
    "    print (metric)\n",
    "    \n",
    "    # Set up splitting scheme, use StratifiedKFold\n",
    "    # use skf_seed and n_splits defined above with shuffle=True\n",
    "    skf = StratifiedKFold(n_splits=n_splits, random_state=skf_seed, shuffle=True)\n",
    "    \n",
    "    # Create instance of our KNN feature extractor\n",
    "    # n_jobs can be larger than the number of cores\n",
    "    NNF = NearestNeighborsFeats(n_jobs=15, k_list=k_list, metric=metric)\n",
    "    print('NNF')\n",
    "    # Get KNN features using OOF use cross_val_predict with right parameters\n",
    "    preds = cross_val_predict(NNF, X, Y, cv=skf)\n",
    "    \n",
    "    # Save the features\n",
    "    np.save('knn_feats_%s_train.npy' % metric, preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "a=_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Submit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you made the above cells work, just run the following cell to produce a number to submit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3838.0\n"
     ]
    }
   ],
   "source": [
    "s = 0\n",
    "for metric in ['minkowski', 'cosine']:\n",
    "    knn_feats_train = np.load('knn_feats_%s_train.npy' % metric)\n",
    "    knn_feats_test = np.load('knn_feats_%s_test.npy' % metric)\n",
    "    \n",
    "    s += knn_feats_train.mean() + knn_feats_test.mean()\n",
    "    \n",
    "answer = np.floor(s)\n",
    "print (answer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Submit!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current answer for task statistic is: 3838.0\n",
      "You want to submit these numbers:\n",
      "Task statistic: 3838.0\n",
      "Submitted to Coursera platform. See results on assignment page!\n"
     ]
    }
   ],
   "source": [
    "from grader import Grader\n",
    "\n",
    "grader = Grader()\n",
    "\n",
    "grader.submit_tag('statistic', answer)\n",
    "\n",
    "STUDENT_EMAIL = 'alessandro.solbiati@post.com'\n",
    "STUDENT_TOKEN = 'XTv5gl22jZQL3X3G'\n",
    "grader.status()\n",
    "\n",
    "grader.submit(STUDENT_EMAIL, STUDENT_TOKEN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
